#!/bin/bash
###############################################################################
# CONFIGURATION
###############################################################################
# shellcheck source=config
########## CONFIGURATION ##########
. "INSERT_CONFIG_FILE"
###################################

##############################################################################

# Set Move/Copy based on move_ind
if [ "${move_ind}" = "1" ]; then
	copy_cmd="move"
else
	copy_cmd="copy"	
fi
	

# If script is already running; abort.
if pidof -o %PPID -x "$(basename "$0")"; then
	echo "[ $(date ${date_format}) ] Upload already in progress. Aborting."
	exit 3
fi

echo "[ $(date ${date_format}) ] ###### Start cloud upload ######"

oldSize=0
addedSize=0

# Generate filelist and iterate through it...
find "${local_decrypt_dir}" -type f -print0 | xargs -0 stat --format '%Y :%y %n' | sort -nr | cut -d: -f2- | awk '{$1=$2=$3=""; print $0}' |
	while read -r n; do

		# Find the pathname relative to the root of your remote and store filename
		filename="$(echo "$n" | sed -e s@"${local_decrypt_dir}"@@)"
		destpath="$(dirname "$n" | sed -e s@"${local_decrypt_dir}"@@)"

		# Skip hidden or partial files.
		case "$n" in
			(*.partial~) continue ;;
			(*_HIDDEN~) continue ;;
			(*.QTFS) continue ;;
			(*.fuse*) continue ;;
			(*.inProgress*) continue ;;
			(.DS_STORE) continue ;;
		esac

		if [ -f "${cloud_decrypt_dir}${filename}" ]; then
            continue
        fi

		# If file is opened by another process, wait until it isn't.
		while [ "$(lsof "$n" >/dev/null 2>&1)" ] || \
			[ "$(lsof "${local_decrypt_dir}/${n}" >/dev/null 2>&1)" ] || \
			[ "$(lsof "${local_media_dir}/${n}" >/dev/null 2>&1)" ]; do
			echo "[ $(date ${date_format}) ] File -> ${n} in use. Retrying in 10 seconds."
			sleep 10
		done

		fileSize=$(du -sb "$n" | awk '{print $1}')
		addedSize=$((addedSize + fileSize))
		sizeInMb=$((addedSize / 1000 / 1000))

		if [[ "${upload_limit}" -gt "0" ]]; then
			if [[ "$((sizeInMb / 1000))" -gt "${upload_limit}" ]]; then
				echo "[ $(date ${date_format}) ] Aborted upload to not exceed ${upload_limit}GB."
				echo "[ $(date ${date_format}) ] $((oldSize / 1000 / 1000 / 1000))GB uploaded"
                break
			fi
		fi

		# Copy/Move file to remote destination[s], retaining path
		"${rclone_bin}" "${copy_cmd}" --config="${rclone_config}" $rclone_options "$n" "${rclone_cloud_endpoint}${destpath}" >/dev/null 2>&1


        diffSize=$((addedSize - oldSize))
        if [[ "${sizeInMb}" -gt 1000 ]]; then
                if [[ "${diffSize}" -gt "1000000000" ]]; then # greater than 1 GB
                        oldSize=$addedSize
                        echo "[ $(date ${date_format}) ] $((sizeInMb / 1000)) GB uploaded"
                fi
        elif [[ "${diffSize}" -gt "100000000" ]]; then # greater than 100 MB
                oldSize=$addedSize
                echo "[ $(date ${date_format}) ] ${sizeInMb} MB uploaded"
        fi
	done

echo "[ $(date ${date_format}) ] ###### Cloud upload ended successfully ######"
